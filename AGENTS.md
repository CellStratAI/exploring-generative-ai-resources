## ðŸ”¥  AUTONOMOUS AGENTS
ðŸ”¥ Must-read papers for LLM-based agents.

## Agents

1. **[A Survey on Large Language Model based Autonomous Agents](https://arxiv.org/pdf/2308.11432.pdf)**  
Autonomous agents have long been a
research focus in academic and industry communities. Previous research often focuses on training
agents with limited knowledge within isolated environments, which diverges significantly from human
learning processes, and makes the agents hard to
achieve human-like decisions. Recently, through
the acquisition of vast amounts of web knowledge,
large language models (LLMs) have shown potential in human-level intelligence, leading to a surge in
research on LLM-based autonomous agents. 


2. **[An Open-source Framework for Autonomous Language Agents](https://github.com/aiwaves-cn/agents)** 
Agents is an open-source library/framework for building autonomous language agents. The library is carefully engineered to support important features including long-short term memory, tool usage, web navigation, multi-agent communication, and brand new features including human-agent interaction and symbolic control. With Agents, one can customize a language agent or a multi-agent system by simply filling in a config file in natural language and deploy the language agents in a terminal, a Gradio interface, or a backend service.

3. **[The Rise and Potential of Large Language Model Based Agents: A Survey](https://github.com/aiwaves-cn/agents)** 
For a long time, humanity has pursued artificial intelligence (AI) equivalent to or
surpassing the human level, with AI agents considered a promising vehicle for
this pursuit.

4. **[The Rise and Potential of Large Language Model Based Agents: A Survey](https://github.com/woooodyy/llm-agent-paper-list)** 

5. **[KnowAgent: Knowledge-Augmented Planning for LLM-Based Agents ](https://arxiv.org/abs/2403.03101)** 
Large Language Models (LLMs) have demonstrated great potential in complex reasoning tasks, yet they fall short when tackling more sophisticated challenges, especially when interacting with environments through generating executable actions. 

6. **[An Easy-to-use Instruction Processing Framework for Large Language Models](https://arxiv.org/pdf/2402.03049.pdf)** 
To construct highquality instruction datasets, many instruction
processing approaches have been proposed,
aiming to achieve a delicate balance between
data quantity and data quality.

7. **[A Comprehensive Study of Knowledge Editing for Large Language Models](https://arxiv.org/pdf/2401.01286.pdf)** 
Large Language Models (LLMs) have shown extraordinary capabilities in understanding and generating text that closely mirrors human communication. However, a primary limitation lies in the significant computational demands during training, arising from their extensive parameterization. This challenge is further intensified by the dynamic nature of the world, necessitating frequent updates to LLMs to correct outdated information or integrate new knowledge, thereby ensuring their continued relevance. 

8. **[Promising and worth-to-try future directions for advancing state-of-the-art surrogates methods of agent-based models in social and health computational sciences](https://arxiv.org/abs/2403.04417)** 
The execution and runtime performance of model-based analysis tools for realistic large-scale ABMs (Agent-Based Models) can be excessively long. This due to the computational demand exponentially proportional to the model size (e.g. Population size) and the number of model parameters. Even the runtime of a single simulation of a realistic ABM may demand huge computational resources when attempting to employ realistic population size. 





